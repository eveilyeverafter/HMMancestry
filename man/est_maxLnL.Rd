% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/Est_max_LnL.R
\name{est_maxLnL}
\alias{est_maxLnL}
\title{Numerically Estimating the Maximum LnL parameter values from the data}
\usage{
est_maxLnL(dat, ploidy = "diploid", initial_p_assign = "NULL",
  initial_scale = "NULL", tolerance = 0.001, n_coarse_steps = 5,
  n_iterations = 30, plot = FALSE)
}
\arguments{
\item{dat}{a data.frame with five columns:
  \itemize{
        \item \code{Ind}{ The individual ID}
        \item \code{Chr}{ The chromosome ID}
        \item \code{Snp}{ The (sorted) snp location (in bps)}
        \item \code{p0}{ The number of reads that mapped to parent 0}
        \item \code{p1}{ The number of reads that mapped to parent 1}
    }
Note that the names of the columns can be different and there can be additional columns to the right (\code{est_maxLnL} only uses the
first 5 columns of the data.frame).}

\item{\code{ploidy}}{The ploidy to analyze. If \code{ploidy="diploid"} (default) then
\code{\link{fb_diploid}} is used to infer states and estimate likelihood. If \code{ploidy="haploid"}
then \code{\link{fb_haploid}} will be used.}

\item{\code{initial_p_assign}}{The initial assignment probability (see details). If "NULL" (default), then a coarse search will be performed with
\code{n_coarse_steps} equally spaced from 0.95 to 0.999.}

\item{\code{initial_scale}}{The initial genome-wide recombination rate (Morgans / bp).
If "NULL" (default), then a coarse search will be performed \code{n_coarse_steps} equally spaced from
1e-06 to 1e-04.}

\item{\code{tolerance}}{The tolerance used to stop the search.}

\item{\code{n_coarse_steps}}{The size of the 1D (if either \code{initial_p_assign} or \code{initial_scale} is "NULL") or
2D grid (if both are "NULL"). Increasing \code{n_coarse_steps} can greatly increase computation time.}

\item{\code{n_iterations}}{The number of iterations during the fine scale parameter estimate serach (see details).}
}
\value{
A data.frame containing the following columns:
\itemize{
     \item{p_assign_hat}{ An estimate of the assignment probability}
     \item{scale_hat}{ An estimate of mean recombination rate}
     \item{n_iterations}{ The number of iterations carried out}
     }
}
\description{
Infers the genome-wide recombination rate (Morgans / bp) and the assignment
probabilty directly from the data using maximum likelihood estimates.
}
\details{
\code{est_maxLnL} has a coarse and fine scale method to estimate
the genome-wide recombination rate, \eqn{\hat{c}}, and assignement probability, \eqn{\hat{p}}.
The coarse scale uses either \code{fb_haploid} or \code{fb_diploid} output and estimates
the natural log-likelihood, LnL, of the data across a coarse (in parameter space) grid of varying
\eqn{p} or \eqn{c} values and the fine scale uses a two-variable Newton-Raphson method to hone
in on a closer estimate. For further details see Hether et al. (in prep).
}
\examples{
# Simulating 30 haploid recombinants
set.seed(1234567)        # For reproducibility
n_spores <- 30           # number of recombinants
l <- 1000                # number of snps to simulate
c <- 1e-06               # recombination rate between snps (Morgan/bp)
snps <- c(1:l)*1e2       # snps are evenly spaced 100bps apart
p_a <- 0.985             # assignment probability
coverage <- 1            # mean coverage
# Now simulate
sim <- sim_en_masse(n.spores=n_spores, scale=c, snps=snps,
	p.assign=p_a, mu.rate=0, f.cross=1, f.convert=0,
	length.conversion=0, coverage=coverage)
# Now estmate params
res <- est_maxLnL(sim, ploidy="haploid", plot=TRUE)
res
}
\author{
Tyler D. Hether
}
\references{
Hether, T.D., C. G. Wiench1, and P.A. Hohenlohe (in review). 2015. Novel molecular and analytical tools
for efficient estimation of rates of meiotic crossover, non-crossover and gene conversion

P. Deuflhard, Newton Methods for Nonlinear Problems. Affine Invariance and Adaptive Algorithms. Springer
Series in Computational Mathematics, Vol. 35. Springer, Berlin, 2004.
}
\seealso{
\code{\link{fb_haploid}}, \code{\link{fb_haploid}}
}

